{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNGK6uZboRnMv1j7oEtkjV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaswanth-03/Data_analysis_-univariate-bivariate-multivariate-/blob/main/bivariate_and_multivariate_anlaysis_on_categoical_column.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bivariate and multivariate anlaysis on categoical column"
      ],
      "metadata": {
        "id": "ViS1u3EdTPIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chi-Square Test of Independence"
      ],
      "metadata": {
        "id": "vqoZOOqLveIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVUU-kubRhU_",
        "outputId": "e9ce415f-4bf9-4046-d666-546b55fbd49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-square Statistic: 0.7936507936507936\n",
            "P-value: 0.9392972321151757\n",
            "Fail to reject the null hypothesis: There is no significant association between the categorical variables.\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample contingency table\n",
        "#            | Category A | Category B | Category C |\n",
        "# ---------------------------------------------------\n",
        "# Group 1    |     10     |     20     |     30     |\n",
        "# ---------------------------------------------------\n",
        "# Group 2    |     15     |     25     |     35     |\n",
        "# ---------------------------------------------------\n",
        "# Group 3    |     20     |     30     |     40     |\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# Contingency table data\n",
        "observed_frequencies = [[10, 20, 30],\n",
        "                        [15, 25, 35],\n",
        "                        [20, 30, 40]]\n",
        "\n",
        "# Chi-Square Test of Independence\n",
        "\"\"\"\n",
        "Explanation:\n",
        "- The Chi-Square Test of Independence is used to determine whether there is a significant association between two categorical variables.\n",
        "- It tests the null hypothesis that the two categorical variables are independent of each other.\n",
        "- If the calculated p-value is less than the chosen significance level (e.g., 0.05), we reject the null hypothesis and conclude that there is a significant association between the variables.\n",
        "\"\"\"\n",
        "\n",
        "# Perform Chi-Square Test of Independence\n",
        "chi2_statistic, p_value, _, _ = chi2_contingency(observed_frequencies)\n",
        "\n",
        "# Print results\n",
        "print(\"Chi-square Statistic:\", chi2_statistic)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Decision based on p-value\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant association between the categorical variables.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant association between the categorical variables.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# contingency table"
      ],
      "metadata": {
        "id": "mUX2QbX_vluC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset with categorical variables\n",
        "data = {\n",
        "    'Category_A': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "    'Category_B': ['X', 'Y', 'X', 'Y', 'X', 'Y']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Contingency table\n",
        "contingency_table = pd.crosstab(df['Category_A'], df['Category_B'])\n",
        "\n",
        "# Calculate row percentages\n",
        "row_percentages = contingency_table.div(contingency_table.sum(axis=1), axis=0)\n",
        "\n",
        "# Calculate column percentages\n",
        "column_percentages = contingency_table.div(contingency_table.sum(axis=0), axis=1)\n",
        "\n",
        "# Print contingency table\n",
        "print(\"Contingency Table:\")\n",
        "print(contingency_table)\n",
        "\n",
        "# Print row percentages\n",
        "print(\"\\nRow Percentages:\")\n",
        "print(row_percentages)\n",
        "\n",
        "# Print column percentages\n",
        "print(\"\\nColumn Percentages:\")\n",
        "print(column_percentages)\n",
        "\n",
        "\n",
        "data1 = {\n",
        "    'Category_A': ['Yes', 'No', 'Yes', 'Yes', 'No'],\n",
        "    'Category_B': ['High', 'Low', 'Medium', 'High', 'Low']\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data1)\n",
        "\n",
        "# Constructing a contingency table\n",
        "contingency_table = pd.crosstab(df['Category_A'], df['Category_B'])\n",
        "\n",
        "\n",
        "# Calculate odds ratios\n",
        "# Assuming 'Yes' as the reference category for Category_A\n",
        "odds_ratios = pd.DataFrame()\n",
        "odds_ratios['Low'] = contingency_table.loc['Yes'] / contingency_table.loc['No']\n",
        "odds_ratios['Medium'] = contingency_table.loc['Yes'] / contingency_table.loc['No']\n",
        "odds_ratios['High'] = contingency_table.loc['Yes'] / contingency_table.loc['No']\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"Contingency Table:\")\n",
        "print(contingency_table)\n",
        "\n",
        "print(\"\\nOdds Ratios (with 'Yes' as reference category for Category_A):\")\n",
        "print(odds_ratios)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbSszqJHTgdW",
        "outputId": "30633822-0611-4875-9bbe-2a7a0a4cd6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contingency Table:\n",
            "Category_B  X  Y\n",
            "Category_A      \n",
            "A           1  1\n",
            "B           1  1\n",
            "C           1  1\n",
            "\n",
            "Row Percentages:\n",
            "Category_B    X    Y\n",
            "Category_A          \n",
            "A           0.5  0.5\n",
            "B           0.5  0.5\n",
            "C           0.5  0.5\n",
            "\n",
            "Column Percentages:\n",
            "Category_B         X         Y\n",
            "Category_A                    \n",
            "A           0.333333  0.333333\n",
            "B           0.333333  0.333333\n",
            "C           0.333333  0.333333\n",
            "Contingency Table:\n",
            "Category_B  High  Low  Medium\n",
            "Category_A                   \n",
            "No             0    2       0\n",
            "Yes            2    0       1\n",
            "\n",
            "Odds Ratios (with 'Yes' as reference category for Category_A):\n",
            "            Low  Medium  High\n",
            "Category_B                   \n",
            "High        inf     inf   inf\n",
            "Low         0.0     0.0   0.0\n",
            "Medium      inf     inf   inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chi-Square Test\n",
        "# Cramer's V calculation"
      ],
      "metadata": {
        "id": "amaLugiOvrBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "categorical_data1 = ['A', 'A', 'B', 'C', 'A', 'B', 'C', 'B']\n",
        "categorical_data2 = ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y']\n",
        "\n",
        "# Contingency table (replace with your actual data)\n",
        "contingency_table = np.crosstab(categorical_data1, categorical_data2)\n",
        "\n",
        "# Chi-Square Test (performed for completeness)\n",
        "chi2_statistic, p_value, degrees_of_freedom, expected_table = chi2_contingency(contingency_table)\n",
        "\n",
        "# Cramer's V calculation\n",
        "n = np.sum(contingency_table)  # Total number of observations\n",
        "k1 = len(set(categorical_data1))  # Number of categories in variable 1\n",
        "k2 = len(set(categorical_data2))  # Number of categories in variable 2\n",
        "chi2 = chi2_statistic  # Chi-square statistic from the test\n",
        "\n",
        "cramer_v = np.sqrt(chi2 / (n * min(k1 - 1, k2 - 1)))\n",
        "\n",
        "# Interpretation\n",
        "print(\"Cramer's V:\", cramer_v)\n",
        "\n",
        "# Interpretation Guidelines (reference values may vary)\n",
        "# 0 - 0.2: Weak association\n",
        "# 0.2 - 0.4: Moderate association\n",
        "# 0.4 - 1.0: Strong association\n"
      ],
      "metadata": {
        "id": "gfnMV-5kWczj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "categorical_data1 = ['A', 'A', 'B', 'C', 'A', 'B', 'C', 'B']\n",
        "categorical_data2 = ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y']\n",
        "\n",
        "# Contingency table using Pandas crosstab\n",
        "contingency_table = pd.crosstab(categorical_data1, categorical_data2)\n",
        "\n",
        "# Chi-Square Test (performed for completeness)\n",
        "chi2_statistic, p_value, degrees_of_freedom, expected_table = chi2_contingency(contingency_table.values)  # Use .values to convert to NumPy array\n",
        "\n",
        "# Cramer's V calculation\n",
        "n = np.sum(contingency_table.values)  # Total number of observations\n",
        "k1 = len(set(categorical_data1))  # Number of categories in variable 1\n",
        "k2 = len(set(categorical_data2))  # Number of categories in variable 2\n",
        "chi2 = chi2_statistic  # Chi-square statistic from the test\n",
        "\n",
        "cramer_v = np.sqrt(chi2 / (n * min(k1 - 1, k2 - 1)))\n",
        "\n",
        "# Interpretation\n",
        "print(\"Cramer's V:\", cramer_v)\n",
        "\n",
        "# Interpretation Guidelines (reference values may vary)\n",
        "# 0 - 0.2: Weak association\n",
        "# 0.2 - 0.4: Moderate association\n",
        "# 0.4 - 1.0: Strong association\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAZgy6FbbC_w",
        "outputId": "ddf14f0b-119f-44ce-e213-056488e0539e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cramer's V: 0.28867513459481287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Chi-square Test of Independence\n"
      ],
      "metadata": {
        "id": "KY-haNAvv5mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# Summary of Comments explaining the code:\n",
        "# - The sample contingency table represents observed frequencies of two binary variables.\n",
        "# - The Phi coefficient measures the strength of association between the binary variables in the contingency table.\n",
        "# - It is equivalent to the Pearson correlation coefficient for binary variables.\n",
        "# - The Phi coefficient ranges from 0 to 1, indicating the strength of association between the variables.\n",
        "# - This code snippet demonstrates how to calculate the Phi coefficient using the chi-square test of independence and numpy functions.\n",
        "# - The Phi coefficient is commonly used in bivariate analysis for assessing association between binary variables.\n",
        "# \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample contingency table for two binary variables\n",
        "#           | Variable 1 | Variable 2 |\n",
        "# ---------------------------------------\n",
        "# Group 1   |     10     |     20     |\n",
        "# ---------------------------------------\n",
        "# Group 2   |     15     |     35     |\n",
        "# ---------------------------------------\n",
        "\n",
        "# Contingency table data\n",
        "observed_frequencies = np.array([[10, 20],\n",
        "                                 [15, 35]])\n",
        "\n",
        "# Chi-square Test of Independence\n",
        "chi2_statistic, _, _, _ = chi2_contingency(observed_frequencies)\n",
        "\n",
        "# Calculate Phi coefficient\n",
        "phi_coefficient = np.sqrt(chi2_statistic / np.sum(observed_frequencies))\n",
        "\n",
        "# Print Phi coefficient\n",
        "print(\"Phi Coefficient:\", phi_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpqfB5qMbFCg",
        "outputId": "9e0bc50c-c426-4d88-950e-ded2063a0304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phi Coefficient: 0.006963106238227913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print Point-Biserial Correlation\n"
      ],
      "metadata": {
        "id": "FhwY9vLjv-2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# Summary of Comments explaining the code:\n",
        "# - Point-Biserial Correlation measures the correlation between one binary variable and one continuous variable.\n",
        "# - It quantifies the strength and direction of the relationship between the variables.\n",
        "# - This correlation coefficient ranges from -1 to 1, where:\n",
        "#     - 0 indicates no correlation.\n",
        "#     - Positive values indicate a positive correlation.\n",
        "#     - Negative values indicate a negative correlation.\n",
        "# - The point-biserial correlation is calculated using the pointbiserialr function from scipy.stats module.\n",
        "# - It is commonly used in bivariate analysis to assess the association between a binary variable and a continuous variable.\n",
        "# \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import pointbiserialr\n",
        "\n",
        "# Sample data for one binary variable and one continuous variable\n",
        "binary_variable = np.array([0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
        "continuous_variable = np.array([2.5, 3.5, 4.2, 1.8, 5.1, 2.9, 4.7, 2.2, 5.0, 3.0])\n",
        "\n",
        "# Calculate Point-Biserial Correlation\n",
        "point_biserial_corr, p_value = pointbiserialr(binary_variable, continuous_variable)\n",
        "\n",
        "# Print Point-Biserial Correlation\n",
        "print(\"Point-Biserial Correlation:\", point_biserial_corr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViaIhPI6dE6Y",
        "outputId": "84909842-4dad-42d8-ce91-994b583622d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Point-Biserial Correlation: 0.8882575468660793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spearman's Rank Correlation"
      ],
      "metadata": {
        "id": "-V6SivUowDiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Summary of Comments explaining the code:\n",
        "- Spearman's Rank Correlation is a non-parametric measure used to assess the strength and direction of the monotonic relationship between two ordinal variables.\n",
        "- It is based on the ranks of the values rather than their actual numerical values.\n",
        "- This correlation coefficient ranges from -1 to 1, where:\n",
        "    - 0 indicates no correlation.\n",
        "    - Positive values indicate a positive correlation.\n",
        "    - Negative values indicate a negative correlation.\n",
        "- Spearman's Rank Correlation is robust to outliers and does not assume linearity.\n",
        "- It is commonly used when analyzing relationships between variables that are measured on an ordinal scale or when the assumptions of Pearson's correlation are violated.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Sample data for two ordinal variables\n",
        "variable1 = np.array([5, 7, 3, 8, 2])\n",
        "variable2 = np.array([10, 8, 6, 4, 2])\n",
        "\n",
        "# Calculate Spearman's Rank Correlation\n",
        "spearman_corr, p_value = spearmanr(variable1, variable2)\n",
        "\n",
        "# Print Spearman's Rank Correlation\n",
        "print(\"Spearman's Rank Correlation:\", spearman_corr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGpmXseIdTFb",
        "outputId": "dc69e887-7311-4b03-98d7-ead42f672cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's Rank Correlation: 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prince"
      ],
      "metadata": {
        "id": "nlzPxCGUeuPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Correspondence Analysis (MCA)"
      ],
      "metadata": {
        "id": "KQKMqksfwIfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Summary of Comments explaining the code:\n",
        "- Multiple Correspondence Analysis (MCA) is a multivariate statistical technique used to explore relationships among multiple categorical variables simultaneously.\n",
        "- It is an extension of Principal Component Analysis (PCA) for categorical data.\n",
        "- MCA aims to represent the categorical variables in a lower-dimensional space while preserving their relationships.\n",
        "- This method is useful for visualizing and understanding the structure of categorical data, identifying patterns, and detecting associations between categories.\n",
        "- MCA is commonly used in fields such as market research, social sciences, and bioinformatics for analyzing categorical data with multiple variables.\n",
        "\"\"\"\n",
        "\n",
        "from prince import MCA\n",
        "import pandas as pd\n",
        "\n",
        "# Sample categorical dataset with multiple variables\n",
        "data = pd.DataFrame({\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Male', 'Female'],\n",
        "    'Age Group': ['Young', 'Young', 'Middle-aged', 'Middle-aged', 'Young'],\n",
        "    'Education Level': ['High School', 'College', 'College', 'High School', 'Graduate'],\n",
        "    'Employment Status': ['Employed', 'Unemployed', 'Employed', 'Employed', 'Unemployed']\n",
        "})\n",
        "\n",
        "# Perform Multiple Correspondence Analysis (MCA)\n",
        "mca = MCA(n_components=2)\n",
        "mca.fit(data)\n",
        "\n",
        "# Access results including coordinates of categories in the lower-dimensional space\n",
        "coordinates = mca.transform(data)\n",
        "\n",
        "# Print the coordinates of categories in the lower-dimensional space\n",
        "print(\"Coordinates of categories in the lower-dimensional space:\")\n",
        "print(coordinates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luE5tB9PeG0Z",
        "outputId": "47dca308-56a3-459e-dff9-eca063aad6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinates of categories in the lower-dimensional space:\n",
            "          0         1\n",
            "0 -0.510730 -0.597593\n",
            "1  0.881053  0.530951\n",
            "2 -0.675748  0.712172\n",
            "3 -0.939311 -0.234317\n",
            "4  1.244736 -0.411213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KMeans"
      ],
      "metadata": {
        "id": "oMMxox6swMnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Summary of Comments explaining the code:\n",
        "- Cluster Analysis is a method used to group observations based on similarities in their categorical variable profiles.\n",
        "- Methods such as hierarchical clustering or k-means clustering can be applied to categorical data.\n",
        "- Cluster analysis helps identify natural groupings within the data and can provide insights into the structure and patterns present in the dataset.\n",
        "- It is commonly used in various fields such as marketing, customer segmentation, and social sciences for segmenting datasets into meaningful groups.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Sample categorical dataset\n",
        "data = pd.DataFrame({\n",
        "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Male'],\n",
        "    'Education': ['High School', 'College', 'College', 'Graduate', 'Graduate'],\n",
        "    'Income Bracket': ['Low', 'Medium', 'Medium', 'High', 'High']\n",
        "})\n",
        "\n",
        "# Convert categorical variables to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "data_encoded = data.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Perform K-means clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(data_encoded)\n",
        "\n",
        "# Assign clusters to each observation\n",
        "data['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Print the clustered data\n",
        "print(\"Clustered Data:\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6p6-zR7gsXU",
        "outputId": "2816c147-2559-489f-d143-40ed06872d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustered Data:\n",
            "   Gender    Education Income Bracket  Cluster\n",
            "0    Male  High School            Low        2\n",
            "1  Female      College         Medium        1\n",
            "2  Female      College         Medium        1\n",
            "3    Male     Graduate           High        0\n",
            "4    Male     Graduate           High        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression model"
      ],
      "metadata": {
        "id": "11CqBXL3wUPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Summary of Comments explaining the code:\n",
        "- Logistic Regression is a statistical method used to model the relationship between one binary outcome variable and one or more categorical predictor variables.\n",
        "- It is a type of regression analysis commonly used for binary classification tasks, where the outcome variable is binary (e.g., 0 or 1).\n",
        "- Logistic Regression estimates the probability that the outcome variable belongs to a particular category based on the values of predictor variables.\n",
        "- It is widely used in various fields such as healthcare, finance, and marketing for predictive modeling, hypothesis testing, and understanding the relationship between variables.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample dataset with binary outcome variable and categorical predictor variables\n",
        "data = pd.DataFrame({\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'Education': ['High School', 'College', 'College', 'Graduate', 'Graduate'],\n",
        "    'Income': ['Low', 'Medium', 'Medium', 'High', 'High'],\n",
        "    'Outcome': [0, 1, 0, 1, 0]  # Binary outcome variable\n",
        "})\n",
        "\n",
        "# Encode categorical variables into numerical labels\n",
        "data_encoded = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = data_encoded.drop('Outcome', axis=1)\n",
        "y = data_encoded['Outcome']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit Logistic Regression model\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9j5vJehTmX",
        "outputId": "4855264d-b943-4a73-82b0-a42babc4b70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       1.0\n",
            "   macro avg       0.00      0.00      0.00       1.0\n",
            "weighted avg       0.00      0.00      0.00       1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression"
      ],
      "metadata": {
        "id": "dFTStnQDwYqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Summary of Comments explaining the code:\n",
        "- Multinomial Logistic Regression is an extension of logistic regression that handles multinomial outcome variables with more than two categories.\n",
        "- It models the probabilities of different categories of the outcome variable based on the categorical predictors.\n",
        "- Multinomial Logistic Regression is used for classification tasks where the outcome variable has multiple categories.\n",
        "- It is commonly used in fields such as healthcare (e.g., predicting disease severity), natural language processing (e.g., text classification), and marketing (e.g., customer segmentation).\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample dataset with multinomial outcome variable and categorical predictor variables\n",
        "data = pd.DataFrame({\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'Education': ['High School', 'College', 'College', 'Graduate', 'Graduate'],\n",
        "    'Income': ['Low', 'Medium', 'Medium', 'High', 'High'],\n",
        "    'Outcome': ['ClassA', 'ClassB', 'ClassA', 'ClassC', 'ClassB']  # Multinomial outcome variable\n",
        "})\n",
        "\n",
        "# Convert categorical variables to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Outcome'] = label_encoder.fit_transform(data['Outcome'])\n",
        "\n",
        "# Encode categorical predictor variables into numerical labels\n",
        "data_encoded = pd.get_dummies(data[['Gender', 'Education', 'Income']])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = data_encoded\n",
        "y = data['Outcome']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit Multinomial Logistic Regression model\n",
        "multinomial_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "multinomial_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = multinomial_model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p9GQEvUiexl",
        "outputId": "6b8931b2-a91a-4269-99e8-b59f4d166e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       1.0\n",
            "   macro avg       0.00      0.00      0.00       1.0\n",
            "weighted avg       0.00      0.00      0.00       1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}